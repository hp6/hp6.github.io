<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hayk Poghosyan</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:960px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Hayk Poghosyan
                  </p>
                  <p>I'm a Senior ML research engineer at Pipio, where I work on generative AI for audio-conditioned
                    video generation. Check out our latest project: <a
                      href="https://edit-yourself.github.io/">EditYourself</a>.
                  </p>
                  <p>Previously, I was a senior ML scientist
                    at PicsArt, focusing on large-scale controllable image and video generation using GANs and diffusion
                    models, low-light enhancement and person segmentation. I've also worked on AI
                    website builders, time-series forecasting, and anomaly detection. I have 7+ year in experiance in
                    both research and engineering.</p>
                  <p>I hold a PhD in theoretical physics from the Yerevan Physics Institute, with research spanning
                    classical and quantum spin systems, and a master's degree in informatics and computer engineering.
                    My work bridges computer vision, generative models, and large-scale data systems, with publications
                    at venues including CVPR, JHEP, ICASSP, ACM Multimedia, and Physica A.</p>
                  <p style="text-align:center">
                    <a href="mailto:haykpoghos@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/hayk-poghosyan-793b97198">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=xlxZDMAAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/hp6">GitHub</a>
                  </p>
                  <p class="bio-location" style="text-align:center; margin-top:8px;">
                    üìç Alicante, Spain
                  </p>
                </td>
                <td style="padding:2.5%;width:37%;max-width:37%">
                  <a href="images/hp.png"><img
                      style="width:100%;max-width:70%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/hp.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;">
            <tbody>
              <tr>
                <td style="padding:16px 16px 8px; width:100%; vertical-align:middle">
                  <h2>Experience</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%; border:0; border-spacing:0; border-collapse:separate; margin-right:auto; margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0 16px 24px; width:100%; vertical-align:top">
                  <ul class="experience-list">
                    <li class="experience-item">
                      <div class="experience-card-inner">
                        <img class="experience-logo" src="images/companies/pipio_logo.png" alt="Pipio">
                        <div class="experience-content">
                          <strong>Senior ML Research Engineer</strong> ‚Äî Pipio<br>
                          <span class="experience-date">October 2025 - Present</span>
                          <ul class="experience-duties">
                            <li>Generative AI for audio-conditioned video generation.</li>
                            <li>Deployed and optimized large transformer-based models.</li>
                          </ul>
                        </div>
                      </div>
                    </li>
                    <li class="experience-item">
                      <div class="experience-card-inner">
                        <img class="experience-logo" src="images/companies/Picsart_logo.svg" alt="PicsArt">
                        <div class="experience-content">
                          <strong>Senior ML Scientist</strong> ‚Äî PicsArt<br>
                          <span class="experience-date">September 2021 - September 2025</span>
                          <ul class="experience-duties">
                            <li>Low-light image enhancement with emphasis on controllability.</li>
                            <li>Person semantic segmentation.</li>
                            <li>Image editing using GANs and diffusion models.</li>
                            <li>Image and video generation with generative AI.</li>
                            <li>Processed and managed petabyte-scale image and video datasets.</li>
                          </ul>
                        </div>
                      </div>
                    </li>
                    <li class="experience-item">
                      <div class="experience-card-inner">
                        <img class="experience-logo" src="images/companies/NobleScripts_logo.jpeg" alt="Noble Scripts">
                        <div class="experience-content">
                          <strong>Data Scientist</strong> ‚Äî Noble Scripts<br>
                          <span class="experience-date">April 2021 - September 2021</span>
                          <ul class="experience-duties">
                            <li>Time-series forecasting.</li>
                            <li>Anomaly detection.</li>
                          </ul>
                        </div>
                      </div>
                    </li>
                    <li class="experience-item">
                      <div class="experience-card-inner">
                        <img class="experience-logo" src="images/companies/10Web_logo.png" alt="10Web">
                        <div class="experience-content">
                          <strong>Senior ML Engineer</strong> ‚Äî 10Web<br>
                          <span class="experience-date">Dectember 2018 - April 2021</span>
                          <ul class="experience-duties">
                            <li>Worked on an end-to-end AI Website Builder.</li>
                          </ul>
                        </div>
                      </div>
                    </li>
                    <li class="experience-item">
                      <div class="experience-card-inner">
                        <img class="experience-logo" src="images/companies/YerPhI_logo.ico" alt="YerPhI">
                        <div class="experience-content">
                          <strong>Researcher</strong> ‚Äî YerPhI (Yerevan Physics Institute)<br>
                          <span class="experience-date">2016 - 2025</span>
                          <ul class="experience-duties">
                            <li>Research in theoretical and computational physics.</li>
                            <li>Collaboration with the Demokritos Institute (Athens) on random number generator
                              research.</li>
                          </ul>
                        </div>
                      </div>
                    </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my
                    work focuses on image and video generation, controllable image editing, and inferring structure and
                    semantics from visual data using modern generative models as well as optimizing them for real world
                    loads and usecases.</p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr class="paper-row highlight-row" onmouseout="edityourself_stop()" onmouseover="edityourself_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='edityourself_image'>
                      <img src='https://edit-yourself.github.io/static/images/method.png' width=100%
                        alt="EditYourself method">
                    </div>
                    <img src='https://edit-yourself.github.io/static/images/method.png' width=100%
                      alt="EditYourself method">
                  </div>
                  <script type="text/javascript">
                    function edityourself_start() {
                      document.getElementById('edityourself_image').style.opacity = "1";
                    }

                    function edityourself_stop() {
                      document.getElementById('edityourself_image').style.opacity = "0";
                    }
                    edityourself_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a class="paper-title-link" href="https://edit-yourself.github.io">
                    <span class="papertitle">EditYourself: Audio-Driven Generation and Manipulation of Talking Head
                      Videos with Diffusion Transformers</span>
                    <span class="new-badge">NEW</span>
                  </a>
                  <br>
                  John Flynn,
                  Wolfgang Paier,
                  Dimitar Dinev,
                  Sam Nhut Nguyen,
                  <strong>Hayk Poghosyan,</strong>
                  Manuel Toribio,
                  Sandipan Banerjee,
                  Guy Gafnistrong>
                  <br>
                  <span class="venue-tag">ArXiv</span> 2026
                  <br>
                  <a href="https://edit-yourself.github.io">project page</a>
                  <span class="paper-separator">¬∑</span>
                  <a href="https://arxiv.org/abs/2601.22127">arXiv</a>
                  <p></p>
                  <p>
                    EditYourself is a diffusion-based video editing model for talking heads, enabling transcript-driven
                    lip-syncing, insertion, removal and retiming of speech while preserving identity and visual
                    fidelity.
                  </p>
                </td>
              </tr>

              <tr class="paper-row" onmouseout="streamingt2v_stop()" onmouseover="streamingt2v_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='streamingt2v_image'>
                      <img src='https://streamingt2v.github.io/static/images/teaser.png' width=100%
                        alt="StreamingT2V teaser">
                    </div>
                    <img src='https://streamingt2v.github.io/static/images/teaser.png' width=100%
                      alt="StreamingT2V teaser">
                  </div>
                  <script type="text/javascript">
                    function streamingt2v_start() {
                      document.getElementById('streamingt2v_image').style.opacity = "1";
                    }

                    function streamingt2v_stop() {
                      document.getElementById('streamingt2v_image').style.opacity = "0";
                    }
                    streamingt2v_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://streamingt2v.github.io/">
                    <span class="papertitle">StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation
                      from Text</span>
                  </a>
                  <br>
                  Roberto Henschel,
                  Levon Khachatryan,
                  Daniil Hayrapetyan,
                  <strong>Hayk Poghosyan</strong>,
                  Vahram Tadevosyan,
                  Zhangyang Wang,
                  Shant Navasardyan,
                  Humphrey Shi
                  <br>
                  <span class="venue-tag">CVPR</span> 2025
                  <br>
                  <a href="https://streamingt2v.github.io/">project page</a>
                  <span class="paper-separator">¬∑</span>
                  <a href="https://arxiv.org/abs/2403.14773">arXiv</a>
                  <br>
                  <a href="https://github.com/Picsart-AI-Research/StreamingT2V" style="text-decoration: none;">
                    <img src="https://img.shields.io/github/stars/Picsart-AI-Research/StreamingT2V?style=social"
                      alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
                    <img src="https://img.shields.io/github/forks/Picsart-AI-Research/StreamingT2V?style=social"
                      alt="GitHub forks" style="vertical-align: middle;">
                  </a>
                  <p></p>
                  <p>
                    An autoregressive approach for long video generation (80 to 1200+ frames) with temporal consistency,
                    high motion dynamics, and smooth transitions. Uses a conditional attention module (CAM) and
                    appearance preservation module (APM); includes StreamingSVD (image-to-video) and StreamingModelscope
                    (up to 2 minutes).
                  </p>
                </td>
              </tr>

              <tr class="paper-row" onmouseout="grounded_ip2p_stop()" onmouseover="grounded_ip2p_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='grounded_ip2p_image'>
                      <img
                        src='https://raw.githubusercontent.com/arthur-71/Grounded-Instruct-Pix2Pix/main/src/teaser.png'
                        width=100% alt="Grounded-Instruct-Pix2Pix teaser">
                    </div>
                    <img src='https://raw.githubusercontent.com/arthur-71/Grounded-Instruct-Pix2Pix/main/src/teaser.png'
                      width=100% alt="Grounded-Instruct-Pix2Pix teaser">
                  </div>
                  <script type="text/javascript">
                    function grounded_ip2p_start() {
                      document.getElementById('grounded_ip2p_image').style.opacity = "1";
                    }

                    function grounded_ip2p_stop() {
                      document.getElementById('grounded_ip2p_image').style.opacity = "0";
                    }
                    grounded_ip2p_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://github.com/arthur-71/Grounded-Instruct-Pix2Pix">
                    <span class="papertitle">Grounded-Instruct-Pix2Pix: Improving Instruction Based Image Editing with
                      Automatic Target Grounding</span>
                  </a>
                  <br>
                  Artur Shagidanov,
                  <strong>Hayk Poghosyan</strong>,
                  Xinyu Gong,
                  Zhangyang Wang,
                  Shant Navasardyan,
                  Humphrey Shi
                  <br>
                  <a href="https://github.com/arthur-71/Grounded-Instruct-Pix2Pix">code</a>
                  <br>
                  <a href="https://github.com/arthur-71/Grounded-Instruct-Pix2Pix" style="text-decoration: none;">
                    <img src="https://img.shields.io/github/stars/arthur-71/Grounded-Instruct-Pix2Pix?style=social"
                      alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
                    <img src="https://img.shields.io/github/forks/arthur-71/Grounded-Instruct-Pix2Pix?style=social"
                      alt="GitHub forks" style="vertical-align: middle;">
                  </a>
                  <p></p>
                  <p>
                    A robust framework for localized instruction-based image editing. Two stages: (1) grounding mask
                    extraction via CLIP-Score Filtering and Grounded-SAM, (2) localized editing with Instruct-Pix2Pix
                    and latent blending. Incurs little overhead and requires no additional user inputs.
                  </p>
                </td>
              </tr>

              <tr class="paper-row" onmouseout="recoro_stop()" onmouseover="recoro_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='recoro_image'>
                      <img
                        src='https://raw.githubusercontent.com/Picsart-AI-Research/ReCoRo-Controllable-Low-Light-Image-Enhancement/master/assets/masks_zoom.png'
                        width=100% alt="ReCoRo results">
                    </div>
                    <img
                      src='https://raw.githubusercontent.com/Picsart-AI-Research/ReCoRo-Controllable-Low-Light-Image-Enhancement/master/assets/masks_zoom.png'
                      width=100% alt="ReCoRo results">
                  </div>
                  <script type="text/javascript">
                    function recoro_start() {
                      document.getElementById('recoro_image').style.opacity = "1";
                    }

                    function recoro_stop() {
                      document.getElementById('recoro_image').style.opacity = "0";
                    }
                    recoro_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://github.com/Picsart-AI-Research/ReCoRo-Controllable-Low-Light-Image-Enhancement">
                    <span class="papertitle">ReCoRo: Region-Controllable Robust Light Enhancement by User-Specified
                      Imprecise Masks</span>
                  </a>
                  <br>
                  Dejia Xu,
                  <strong>Hayk Poghosyan</strong>,
                  Shant Navasardyan,
                  Yifan Jiang,
                  Humphrey Shi,
                  Zhangyang Wang
                  <br>
                  <span class="venue-tag">ACM Multimedia</span> 2022
                  <br>
                  <a
                    href="https://github.com/Picsart-AI-Research/ReCoRo-Controllable-Low-Light-Image-Enhancement">code</a>
                  <span class="paper-separator">¬∑</span>
                  <a
                    href="https://github.com/Picsart-AI-Research/ReCoRo-Controllable-Low-Light-Image-Enhancement/blob/master/recoro_paper.pdf">paper
                    (PDF)</a>
                  <br>
                  <a href="https://github.com/Picsart-AI-Research/ReCoRo-Controllable-Low-Light-Image-Enhancement"
                    style="text-decoration: none;">
                    <img
                      src="https://img.shields.io/github/stars/Picsart-AI-Research/ReCoRo-Controllable-Low-Light-Image-Enhancement?style=social"
                      alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
                    <img
                      src="https://img.shields.io/github/forks/Picsart-AI-Research/ReCoRo-Controllable-Low-Light-Image-Enhancement?style=social"
                      alt="GitHub forks" style="vertical-align: middle;">
                  </a>
                  <p></p>
                  <p>
                    A low-light enhancement method that lets users specify where and how much to enhance an input image.
                    Robust to roughly-supplied user masks; supports both imprecise and fine matting masks.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;">
            <tbody>
              <tr>
                <td style="padding:16px 16px 8px; width:100%; vertical-align:middle">
                  <h2>Publications</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%; border:0; border-spacing:0; border-collapse:separate; margin-right:auto; margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0 16px 24px; width:100%; vertical-align:top">
                  <div class="publications-section">
                    <ul class="publications-list">
                      <li class="publication-item">
                        <div class="publication-authors">J. Flynn, W. Paier, D. Dinev, S. N. Nguyen, H. Poghosyan, M.
                          Toribio, S. Banerjee, G. Gafni</div>
                        <div class="publication-title">EditYourself: Audio-Driven Generation and Manipulation of Talking
                          Head Videos with Diffusion Transformers</div>
                        <div class="publication-meta">2026. <a href="https://arxiv.org/abs/2601.22127" target="_blank"
                            rel="noopener">arXiv:2601.22127</a></div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">G. Amatuni, ƒå. Burd√≠k, H. Poghosyan, L. Ananikyan, N. Ananikian
                        </div>
                        <div class="publication-title">Spin-1 Antiferromagnetic Diamond Chains with Biquadratic
                          Nodal-nodal Interactions: Magnetization Plateaus, Super-Stable Points and Cycles</div>
                        <div class="publication-meta">2025. Journal of Physics: Conference Series, 3152, 012036. <a
                            href="https://iopscience.iop.org/article/10.1088/1742-6596/3152/1/012036/meta"
                            target="_blank" rel="noopener">DOI</a></div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">R. Henschel, L. Khachatryan, H. Poghosyan, D. Hayrapetyan, V.
                          Tadevossyan, Z. Wang, S. Navasardyan, H. Shi</div>
                        <div class="publication-title">StreamingT2V: Consistent, Dynamic, and Extendable Long Video
                          Generation from Text</div>
                        <div class="publication-meta">2025. IEEE/CVF CVPR.</div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">A. Shagidanov, H. Poghosyan, X. Gong, Z. Wang, S. Navasardyan,
                          H. Shi</div>
                        <div class="publication-title">Grounded-Instruct-Pix2Pix: Improving Instruction-Based Image
                          Editing with Automatic Target Grounding</div>
                        <div class="publication-meta">2024. IEEE ICASSP.</div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">D. Xu, H. Poghosyan, S. Navasardyan, Y. Jiang, H. Shi, Z. Wang
                        </div>
                        <div class="publication-title">ReCoRo: Region-Controllable Robust Light Enhancement with
                          User-Specified Imprecise Masks</div>
                        <div class="publication-meta">2022. ACM Multimedia (MM '22).</div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">V. Abgaryan, N. Ananikian, L. Ananikyan, H. Poghosyan</div>
                        <div class="publication-title">Magnetic Properties and Entanglement of Nickel Containing Polymer
                        </div>
                        <div class="publication-meta">2019. Armenian Journal of Physics.</div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">H. Poghosyan, K. Savvidy, G. Savvidy</div>
                        <div class="publication-title">Classical limit theorems and high entropy MIX-MAX random number
                          generator</div>
                        <div class="publication-meta">2018. Chaotic Modeling and Simulation. <a
                            href="https://arxiv.org/abs/1708.04129" target="_blank" rel="noopener">arXiv:1708.04129</a>
                        </div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">N. Ananikian, R. Artusov, H. Poghosyan</div>
                        <div class="publication-title">Superstable cycles and magnetization plateau for
                          antiferromagnetic spin-1 Ising and Ising-Heisenberg models on diamond chains</div>
                        <div class="publication-meta">2018. Physica A: Statistical Mechanics and its Applications. <a
                            href="https://doi.org/10.1016/j.physa.2018.03.023" target="_blank" rel="noopener">DOI</a>
                        </div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">H. Poghosyan</div>
                        <div class="publication-title">Super stable cycles and magnetization plateau for spin-1 Ising
                          model on diamond-like decorated Bethe lattice</div>
                        <div class="publication-meta">2017. Armenian Journal of Physics, 10(3), 92-98.</div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">N. Ananikian, ƒå. Burd√≠k, L. Ananikyan, H. Poghosyan</div>
                        <div class="publication-title">Magnetization Plateaus and Thermal Entanglement of Spin Systems
                        </div>
                        <div class="publication-meta">2017. Journal of Physics: Conference Series. <a
                            href="https://doi.org/10.1088/1742-6596/804/1/012002" target="_blank" rel="noopener">DOI</a>
                        </div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">H. Poghosyan, V. Poghosyan</div>
                        <div class="publication-title">Frontal Cellular Automata for the Study of Non-Equilibrium
                          Lattice Models</div>
                        <div class="publication-meta">2015. Computer Science and Information Technologies (CSIT). <a
                            href="https://doi.org/10.1109/CSITechnol.2015.7358248" target="_blank"
                            rel="noopener">DOI</a></div>
                      </li>
                      <li class="publication-item">
                        <div class="publication-authors">A. Poghosyan, H. Poghosyan</div>
                        <div class="publication-title">Mixing with descendant fields in perturbed minimal CFT models
                        </div>
                        <div class="publication-meta">2013. JHEP 1310, 131. <a href="https://arxiv.org/abs/1305.6066"
                            target="_blank" rel="noopener">arXiv:1305.6066</a></div>
                      </li>
                    </ul>
                  </div>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
  </table>
</body>

</html>